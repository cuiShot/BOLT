Model List:
model1:
- Validation set performance: RMSE=3.5885, MAE=2.3442, RMSLE=0.1581
model2:
- Validation set performance: RMSE=3.9637, MAE=2.5003, RMSLE=0.1623
model3:
- Validation set performance: RMSE=4.4063, MAE=2.9993, RMSLE=0.1894
model4:
- Validation set performance: RMSE=3.6421, MAE=2.4030, RMSLE=0.1525
model5:
- Validation set performance: RMSE=4.0396, MAE=2.5760, RMSLE=0.1658

Rescue-Confidence matrix
The Rescue-Confidence matrix is as follows (unit: normalized score in [0,1], rounded to four decimals):
[
 [0.0000, 0.1731, 0.3302, 0.1382, 0.1325],
 [0.2295, 0.0000, 0.2841, 0.1126, 0.0798],
 [0.3159, 0.2298, 0.0000, 0.2370, 0.1725],
 [0.2231, 0.2240, 0.3878, 0.0000, 0.1531],
 [0.2762, 0.1716, 0.2986, 0.1452, 0.0000]
]

Model Output (Recommended Optimal Weight Vector):
Model 1: Weight = 0.36
Model 2: Weight = 0.06
Model 3: Weight = 0.08
Model 4: Weight = 0.42
Model 5: Weight = 0.08

Reasoning for Weight Assignment:
- Model 4: Near-best RMSE (3.6421) and the strongest outbound rescue overall (e.g., rescues Model 3 at 0.3878, 1 at 0.2231, 2 at 0.2240). This makes it a robust “rescuer hub” → assign the largest weight.
- Model 1: Best RMSE (3.5885) and meaningful rescue to Model 3 (0.3302) and 2 (0.1731). It’s the accuracy anchor → assign a large weight.
- Model 3: Weak RMSE, but good at rescuing others (e.g., 4 at 0.2370, 1 at 0.3159). Keep a small weight to harvest rescue-driven gains without overexposing to its own errors.
- Model 5: Moderate outbound rescue (e.g., 3 at 0.2986) and comparatively low inbound need (it’s rescued less by others overall), but raw accuracy lags → small weight.
- Model 2: Lowest outbound rescue among peers and weaker RMSE; retains only a minimal weight for marginal coverage.

Final model weight list: [0.36, 0.06, 0.08, 0.42, 0.08]
